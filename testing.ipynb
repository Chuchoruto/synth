{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN:\n",
      "Pregnancies - Original: 3.8451, Synthetic: 2.9332, Percent Difference: 23.72%\n",
      "Glucose - Original: 120.8945, Synthetic: 107.6811, Percent Difference: 10.93%\n",
      "BloodPressure - Original: 69.1055, Synthetic: 65.4201, Percent Difference: 5.33%\n",
      "SkinThickness - Original: 20.5365, Synthetic: 15.0024, Percent Difference: 26.95%\n",
      "Insulin - Original: 79.7995, Synthetic: 70.3147, Percent Difference: 11.89%\n",
      "BMI - Original: 31.9926, Synthetic: 30.4713, Percent Difference: 4.76%\n",
      "DiabetesPedigreeFunction - Original: 0.4719, Synthetic: 0.2709, Percent Difference: 42.60%\n",
      "Age - Original: 33.2409, Synthetic: 39.2300, Percent Difference: 18.02%\n",
      "Outcome - Original: 0.3490, Synthetic: 0.1824, Percent Difference: 47.73%\n",
      "\n",
      "STD:\n",
      "Pregnancies - Original: 3.3696, Synthetic: 3.5410, Percent Difference: 5.09%\n",
      "Glucose - Original: 31.9726, Synthetic: 31.1526, Percent Difference: 2.56%\n",
      "BloodPressure - Original: 19.3558, Synthetic: 20.8618, Percent Difference: 7.78%\n",
      "SkinThickness - Original: 15.9522, Synthetic: 17.0571, Percent Difference: 6.93%\n",
      "Insulin - Original: 115.2440, Synthetic: 132.1841, Percent Difference: 14.70%\n",
      "BMI - Original: 7.8842, Synthetic: 10.4671, Percent Difference: 32.76%\n",
      "DiabetesPedigreeFunction - Original: 0.3313, Synthetic: 0.3209, Percent Difference: 3.13%\n",
      "Age - Original: 11.7602, Synthetic: 16.0306, Percent Difference: 36.31%\n",
      "Outcome - Original: 0.4770, Synthetic: 0.3862, Percent Difference: 19.03%\n",
      "\n",
      "MIN:\n",
      "Pregnancies - Original: 0.0000, Synthetic: -2.6885, Percent Difference: inf%\n",
      "Glucose - Original: 0.0000, Synthetic: -80.1433, Percent Difference: inf%\n",
      "BloodPressure - Original: 0.0000, Synthetic: -44.1264, Percent Difference: inf%\n",
      "SkinThickness - Original: 0.0000, Synthetic: -6.6188, Percent Difference: inf%\n",
      "Insulin - Original: 0.0000, Synthetic: -217.4623, Percent Difference: inf%\n",
      "BMI - Original: 0.0000, Synthetic: -32.9149, Percent Difference: inf%\n",
      "DiabetesPedigreeFunction - Original: 0.0780, Synthetic: -0.8327, Percent Difference: 1167.58%\n",
      "Age - Original: 21.0000, Synthetic: 16.5096, Percent Difference: 21.38%\n",
      "Outcome - Original: 0.0000, Synthetic: 0.0000, Percent Difference: nan%\n",
      "\n",
      "MAX:\n",
      "Pregnancies - Original: 17.0000, Synthetic: 17.8508, Percent Difference: 5.00%\n",
      "Glucose - Original: 199.0000, Synthetic: 234.1902, Percent Difference: 17.68%\n",
      "BloodPressure - Original: 122.0000, Synthetic: 144.2739, Percent Difference: 18.26%\n",
      "SkinThickness - Original: 99.0000, Synthetic: 66.0876, Percent Difference: 33.24%\n",
      "Insulin - Original: 846.0000, Synthetic: 1022.3073, Percent Difference: 20.84%\n",
      "BMI - Original: 67.1000, Synthetic: 73.8208, Percent Difference: 10.02%\n",
      "DiabetesPedigreeFunction - Original: 2.4200, Synthetic: 3.4824, Percent Difference: 43.90%\n",
      "Age - Original: 81.0000, Synthetic: 89.6536, Percent Difference: 10.68%\n",
      "Outcome - Original: 1.0000, Synthetic: 1.0000, Percent Difference: 0.00%\n",
      "\n",
      "KOLMOGOROV-SMIRNOV TEST:\n",
      "Pregnancies - K-S Statistic: 0.2176, P-value: 0.0000\n",
      "Glucose - K-S Statistic: 0.1931, P-value: 0.0000\n",
      "BloodPressure - K-S Statistic: 0.1916, P-value: 0.0000\n",
      "SkinThickness - K-S Statistic: 0.2707, P-value: 0.0000\n",
      "Insulin - K-S Statistic: 0.2483, P-value: 0.0000\n",
      "BMI - K-S Statistic: 0.1222, P-value: 0.0000\n",
      "DiabetesPedigreeFunction - K-S Statistic: 0.3634, P-value: 0.0000\n",
      "Age - K-S Statistic: 0.2160, P-value: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gk/8dd7zppx4vdg26x_p2w7pkn40000gn/T/ipykernel_7642/3285819046.py:59: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return abs(orig_val - synth_val) / orig_val * 100\n",
      "/var/folders/gk/8dd7zppx4vdg26x_p2w7pkn40000gn/T/ipykernel_7642/3285819046.py:59: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return abs(orig_val - synth_val) / orig_val * 100\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ctgan import CTGAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import ks_2samp\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Separate features and target\n",
    "features = data.drop(columns=['Outcome'])\n",
    "target = data['Outcome']\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "normalized_features = scaler.fit_transform(features)\n",
    "\n",
    "# Combine normalized features with target for CTGAN\n",
    "normalized_data = pd.DataFrame(normalized_features, columns=features.columns)\n",
    "normalized_data['Outcome'] = target.values\n",
    "\n",
    "# Initialize and train CTGAN\n",
    "ctgan = CTGAN()\n",
    "ctgan.fit(normalized_data, epochs=1000)\n",
    "\n",
    "# Sample synthetic data\n",
    "num_samples = len(data)\n",
    "synthetic_data = ctgan.sample(10000)\n",
    "\n",
    "# Inverse transform the normalized features\n",
    "synthetic_features = synthetic_data.drop(columns=['Outcome'])\n",
    "synthetic_features = scaler.inverse_transform(synthetic_features)\n",
    "synthetic_data[features.columns] = synthetic_features\n",
    "\n",
    "# Convert synthetic data to the same format as original data\n",
    "synthetic_data = synthetic_data[normalized_data.columns]\n",
    "\n",
    "# Statistical comparison\n",
    "def compare_statistics(original, synthetic):\n",
    "    stats = {\n",
    "        \"mean\": {},\n",
    "        \"std\": {},\n",
    "        \"min\": {},\n",
    "        \"max\": {},\n",
    "    }\n",
    "\n",
    "    for column in original.columns:\n",
    "        orig_stats = original[column].describe()\n",
    "        synth_stats = synthetic[column].describe()\n",
    "\n",
    "        stats[\"mean\"][column] = (orig_stats[\"mean\"], synth_stats[\"mean\"])\n",
    "        stats[\"std\"][column] = (orig_stats[\"std\"], synth_stats[\"std\"])\n",
    "        stats[\"min\"][column] = (orig_stats[\"min\"], synth_stats[\"min\"])\n",
    "        stats[\"max\"][column] = (orig_stats[\"max\"], synth_stats[\"max\"])\n",
    "\n",
    "    return stats\n",
    "\n",
    "def percent_difference(orig_val, synth_val):\n",
    "    return abs(orig_val - synth_val) / orig_val * 100\n",
    "\n",
    "# Compute statistics\n",
    "stats = compare_statistics(data, synthetic_data)\n",
    "\n",
    "# Print results and percent differences\n",
    "for stat_type, columns in stats.items():\n",
    "    print(f\"\\n{stat_type.upper()}:\")\n",
    "    for column, values in columns.items():\n",
    "        orig_val, synth_val = values\n",
    "        diff = percent_difference(orig_val, synth_val)\n",
    "        print(f\"{column} - Original: {orig_val:.4f}, Synthetic: {synth_val:.4f}, Percent Difference: {diff:.2f}%\")\n",
    "\n",
    "print(\"\\nKOLMOGOROV-SMIRNOV TEST:\")\n",
    "for column in features.columns:\n",
    "    stat, p_value = ks_2samp(data[column], synthetic_data[column])\n",
    "    print(f\"{column} - K-S Statistic: {stat:.4f}, P-value: {p_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN:\n",
      "Pregnancies - Original: 3.8451, Synthetic: 3.8466, Percent Difference: 0.04%\n",
      "Glucose - Original: 120.8945, Synthetic: 121.3848, Percent Difference: 0.41%\n",
      "BloodPressure - Original: 69.1055, Synthetic: 69.0705, Percent Difference: 0.05%\n",
      "SkinThickness - Original: 20.5365, Synthetic: 20.6119, Percent Difference: 0.37%\n",
      "Insulin - Original: 79.7995, Synthetic: 80.6122, Percent Difference: 1.02%\n",
      "BMI - Original: 31.9926, Synthetic: 31.9545, Percent Difference: 0.12%\n",
      "DiabetesPedigreeFunction - Original: 0.4719, Synthetic: 0.4703, Percent Difference: 0.34%\n",
      "Age - Original: 33.2409, Synthetic: 33.2985, Percent Difference: 0.17%\n",
      "Outcome - Original: 0.3490, Synthetic: 0.3490, Percent Difference: 0.00%\n",
      "\n",
      "STD:\n",
      "Pregnancies - Original: 3.3696, Synthetic: 3.3737, Percent Difference: 0.12%\n",
      "Glucose - Original: 31.9726, Synthetic: 31.9484, Percent Difference: 0.08%\n",
      "BloodPressure - Original: 19.3558, Synthetic: 19.3886, Percent Difference: 0.17%\n",
      "SkinThickness - Original: 15.9522, Synthetic: 15.9914, Percent Difference: 0.25%\n",
      "Insulin - Original: 115.2440, Synthetic: 115.5243, Percent Difference: 0.24%\n",
      "BMI - Original: 7.8842, Synthetic: 7.8717, Percent Difference: 0.16%\n",
      "DiabetesPedigreeFunction - Original: 0.3313, Synthetic: 0.3305, Percent Difference: 0.24%\n",
      "Age - Original: 11.7602, Synthetic: 11.7952, Percent Difference: 0.30%\n",
      "Outcome - Original: 0.4770, Synthetic: 0.4770, Percent Difference: 0.00%\n",
      "\n",
      "MIN:\n",
      "Pregnancies - Original: 0.0000, Synthetic: -0.0495, Percent Difference: inf%\n",
      "Glucose - Original: 0.0000, Synthetic: 1.1891, Percent Difference: inf%\n",
      "BloodPressure - Original: 0.0000, Synthetic: -0.4486, Percent Difference: inf%\n",
      "SkinThickness - Original: 0.0000, Synthetic: -0.2701, Percent Difference: inf%\n",
      "Insulin - Original: 0.0000, Synthetic: -1.8210, Percent Difference: inf%\n",
      "BMI - Original: 0.0000, Synthetic: -0.0619, Percent Difference: inf%\n",
      "DiabetesPedigreeFunction - Original: 0.0780, Synthetic: 0.0802, Percent Difference: 2.77%\n",
      "Age - Original: 21.0000, Synthetic: 20.8147, Percent Difference: 0.88%\n",
      "Outcome - Original: 0.0000, Synthetic: 0.0000, Percent Difference: nan%\n",
      "\n",
      "MAX:\n",
      "Pregnancies - Original: 17.0000, Synthetic: 17.0123, Percent Difference: 0.07%\n",
      "Glucose - Original: 199.0000, Synthetic: 199.5909, Percent Difference: 0.30%\n",
      "BloodPressure - Original: 122.0000, Synthetic: 121.9172, Percent Difference: 0.07%\n",
      "SkinThickness - Original: 99.0000, Synthetic: 99.3296, Percent Difference: 0.33%\n",
      "Insulin - Original: 846.0000, Synthetic: 851.0678, Percent Difference: 0.60%\n",
      "BMI - Original: 67.1000, Synthetic: 67.0136, Percent Difference: 0.13%\n",
      "DiabetesPedigreeFunction - Original: 2.4200, Synthetic: 2.4119, Percent Difference: 0.33%\n",
      "Age - Original: 81.0000, Synthetic: 81.1350, Percent Difference: 0.17%\n",
      "Outcome - Original: 1.0000, Synthetic: 1.0000, Percent Difference: 0.00%\n",
      "\n",
      "KOLMOGOROV-SMIRNOV TEST:\n",
      "Pregnancies - K-S Statistic: 0.0938, P-value: 0.0023\n",
      "Glucose - K-S Statistic: 0.0221, P-value: 0.9919\n",
      "BloodPressure - K-S Statistic: 0.0456, P-value: 0.4026\n",
      "SkinThickness - K-S Statistic: 0.1862, P-value: 0.0000\n",
      "Insulin - K-S Statistic: 0.3568, P-value: 0.0000\n",
      "BMI - K-S Statistic: 0.0143, P-value: 1.0000\n",
      "DiabetesPedigreeFunction - K-S Statistic: 0.0130, P-value: 1.0000\n",
      "Age - K-S Statistic: 0.0599, P-value: 0.1272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gk/8dd7zppx4vdg26x_p2w7pkn40000gn/T/ipykernel_7642/905815949.py:95: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return abs(orig_val - synth_val) / orig_val * 100\n",
      "/var/folders/gk/8dd7zppx4vdg26x_p2w7pkn40000gn/T/ipykernel_7642/905815949.py:95: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return abs(orig_val - synth_val) / orig_val * 100\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Separate features and target\n",
    "features = data.drop(columns=['Outcome'])\n",
    "target = data['Outcome']\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "normalized_features = scaler.fit_transform(features)\n",
    "\n",
    "# Convert to torch tensors\n",
    "X = torch.tensor(normalized_features, dtype=torch.float32)\n",
    "y = torch.tensor(target.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Define the neural network\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "input_dim = X.shape[1]\n",
    "output_dim = X.shape[1]\n",
    "\n",
    "generator = Generator(input_dim, output_dim)\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = optim.Adam(generator.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Train the neural network\n",
    "num_epochs = 1000\n",
    "batch_size = 64\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    permutation = torch.randperm(X.size()[0])\n",
    "    for i in range(0, X.size()[0], batch_size):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        indices = permutation[i:i + batch_size]\n",
    "        batch_x, batch_y = X[indices], y[indices]\n",
    "\n",
    "        outputs = generator(batch_x)\n",
    "        loss = criterion(outputs, batch_x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Sample synthetic data\n",
    "with torch.no_grad():\n",
    "    synthetic_data = generator(X).numpy()\n",
    "\n",
    "# Inverse transform the normalized features\n",
    "synthetic_features = scaler.inverse_transform(synthetic_data)\n",
    "synthetic_df = pd.DataFrame(synthetic_features, columns=features.columns)\n",
    "synthetic_df['Outcome'] = target.values\n",
    "\n",
    "# Statistical comparison\n",
    "def compare_statistics(original, synthetic):\n",
    "    stats = {\n",
    "        \"mean\": {},\n",
    "        \"std\": {},\n",
    "        \"min\": {},\n",
    "        \"max\": {},\n",
    "    }\n",
    "\n",
    "    for column in original.columns:\n",
    "        orig_stats = original[column].describe()\n",
    "        synth_stats = synthetic[column].describe()\n",
    "\n",
    "        stats[\"mean\"][column] = (orig_stats[\"mean\"], synth_stats[\"mean\"])\n",
    "        stats[\"std\"][column] = (orig_stats[\"std\"], synth_stats[\"std\"])\n",
    "        stats[\"min\"][column] = (orig_stats[\"min\"], synth_stats[\"min\"])\n",
    "        stats[\"max\"][column] = (orig_stats[\"max\"], synth_stats[\"max\"])\n",
    "\n",
    "    return stats\n",
    "\n",
    "def percent_difference(orig_val, synth_val):\n",
    "    return abs(orig_val - synth_val) / orig_val * 100\n",
    "\n",
    "# Compute statistics\n",
    "stats = compare_statistics(data, synthetic_df)\n",
    "\n",
    "# Print results and percent differences\n",
    "for stat_type, columns in stats.items():\n",
    "    print(f\"\\n{stat_type.upper()}:\")\n",
    "    for column, values in columns.items():\n",
    "        orig_val, synth_val = values\n",
    "        diff = percent_difference(orig_val, synth_val)\n",
    "        print(f\"{column} - Original: {orig_val:.4f}, Synthetic: {synth_val:.4f}, Percent Difference: {diff:.2f}%\")\n",
    "\n",
    "# Kolmogorov-Smirnov Test\n",
    "print(\"\\nKOLMOGOROV-SMIRNOV TEST:\")\n",
    "for column in features.columns:\n",
    "    stat, p_value = ks_2samp(data[column], synthetic_df[column])\n",
    "    print(f\"{column} - K-S Statistic: {stat:.4f}, P-value: {p_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/1000] Discriminator Loss: 1.3351, Generator Loss: 0.6770\n",
      "Epoch [100/1000] Discriminator Loss: 0.8685, Generator Loss: 0.9934\n",
      "Epoch [200/1000] Discriminator Loss: 0.7726, Generator Loss: 1.6361\n",
      "Epoch [300/1000] Discriminator Loss: 0.6548, Generator Loss: 1.4359\n",
      "Epoch [400/1000] Discriminator Loss: 0.6083, Generator Loss: 1.8280\n",
      "Epoch [500/1000] Discriminator Loss: 0.7406, Generator Loss: 1.4959\n",
      "Epoch [600/1000] Discriminator Loss: 1.0855, Generator Loss: 1.5295\n",
      "Epoch [700/1000] Discriminator Loss: 1.0166, Generator Loss: 1.3697\n",
      "Epoch [800/1000] Discriminator Loss: 1.2088, Generator Loss: 0.9091\n",
      "Epoch [900/1000] Discriminator Loss: 1.3762, Generator Loss: 0.9508\n",
      "\n",
      "MEAN:\n",
      "Pregnancies - Original: 3.8451, Synthetic: 3.7287, Percent Difference: 3.03%\n",
      "Glucose - Original: 120.8945, Synthetic: 106.3909, Percent Difference: 12.00%\n",
      "BloodPressure - Original: 69.1055, Synthetic: 67.7193, Percent Difference: 2.01%\n",
      "SkinThickness - Original: 20.5365, Synthetic: 21.0729, Percent Difference: 2.61%\n",
      "Insulin - Original: 79.7995, Synthetic: 122.9715, Percent Difference: 54.10%\n",
      "BMI - Original: 31.9926, Synthetic: 33.8269, Percent Difference: 5.73%\n",
      "DiabetesPedigreeFunction - Original: 0.4719, Synthetic: 0.4398, Percent Difference: 6.81%\n",
      "Age - Original: 33.2409, Synthetic: 29.8226, Percent Difference: 10.28%\n",
      "Outcome - Original: 0.3490, Synthetic: 0.3490, Percent Difference: 0.00%\n",
      "\n",
      "STD:\n",
      "Pregnancies - Original: 3.3696, Synthetic: 2.5986, Percent Difference: 22.88%\n",
      "Glucose - Original: 31.9726, Synthetic: 23.7015, Percent Difference: 25.87%\n",
      "BloodPressure - Original: 19.3558, Synthetic: 6.8743, Percent Difference: 64.48%\n",
      "SkinThickness - Original: 15.9522, Synthetic: 12.2176, Percent Difference: 23.41%\n",
      "Insulin - Original: 115.2440, Synthetic: 113.6750, Percent Difference: 1.36%\n",
      "BMI - Original: 7.8842, Synthetic: 5.8383, Percent Difference: 25.95%\n",
      "DiabetesPedigreeFunction - Original: 0.3313, Synthetic: 0.2564, Percent Difference: 22.60%\n",
      "Age - Original: 11.7602, Synthetic: 11.5599, Percent Difference: 1.70%\n",
      "Outcome - Original: 0.4770, Synthetic: 0.4770, Percent Difference: 0.00%\n",
      "\n",
      "MIN:\n",
      "Pregnancies - Original: 0.0000, Synthetic: -0.7859, Percent Difference: inf%\n",
      "Glucose - Original: 0.0000, Synthetic: 55.2954, Percent Difference: inf%\n",
      "BloodPressure - Original: 0.0000, Synthetic: 30.9678, Percent Difference: inf%\n",
      "SkinThickness - Original: 0.0000, Synthetic: -21.1231, Percent Difference: inf%\n",
      "Insulin - Original: 0.0000, Synthetic: -19.0150, Percent Difference: inf%\n",
      "BMI - Original: 0.0000, Synthetic: 16.2513, Percent Difference: inf%\n",
      "DiabetesPedigreeFunction - Original: 0.0780, Synthetic: -0.0494, Percent Difference: 163.36%\n",
      "Age - Original: 21.0000, Synthetic: 11.8673, Percent Difference: 43.49%\n",
      "Outcome - Original: 0.0000, Synthetic: 0.0000, Percent Difference: nan%\n",
      "\n",
      "MAX:\n",
      "Pregnancies - Original: 17.0000, Synthetic: 14.3527, Percent Difference: 15.57%\n",
      "Glucose - Original: 199.0000, Synthetic: 183.7170, Percent Difference: 7.68%\n",
      "BloodPressure - Original: 122.0000, Synthetic: 84.8030, Percent Difference: 30.49%\n",
      "SkinThickness - Original: 99.0000, Synthetic: 49.7680, Percent Difference: 49.73%\n",
      "Insulin - Original: 846.0000, Synthetic: 656.6526, Percent Difference: 22.38%\n",
      "BMI - Original: 67.1000, Synthetic: 55.3554, Percent Difference: 17.50%\n",
      "DiabetesPedigreeFunction - Original: 2.4200, Synthetic: 1.7605, Percent Difference: 27.25%\n",
      "Age - Original: 81.0000, Synthetic: 88.6225, Percent Difference: 9.41%\n",
      "Outcome - Original: 1.0000, Synthetic: 1.0000, Percent Difference: 0.00%\n",
      "\n",
      "KOLMOGOROV-SMIRNOV TEST:\n",
      "Pregnancies - K-S Statistic: 0.2448, P-value: 0.0000\n",
      "Glucose - K-S Statistic: 0.2188, P-value: 0.0000\n",
      "BloodPressure - K-S Statistic: 0.3008, P-value: 0.0000\n",
      "SkinThickness - K-S Statistic: 0.2422, P-value: 0.0000\n",
      "Insulin - K-S Statistic: 0.4740, P-value: 0.0000\n",
      "BMI - K-S Statistic: 0.1576, P-value: 0.0000\n",
      "DiabetesPedigreeFunction - K-S Statistic: 0.1406, P-value: 0.0000\n",
      "Age - K-S Statistic: 0.2435, P-value: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gk/8dd7zppx4vdg26x_p2w7pkn40000gn/T/ipykernel_7642/656960758.py:135: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return abs(orig_val - synth_val) / orig_val * 100\n",
      "/var/folders/gk/8dd7zppx4vdg26x_p2w7pkn40000gn/T/ipykernel_7642/656960758.py:135: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return abs(orig_val - synth_val) / orig_val * 100\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Separate features and target\n",
    "features = data.drop(columns=['Outcome'])\n",
    "target = data['Outcome']\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "normalized_features = scaler.fit_transform(features)\n",
    "\n",
    "# Convert to torch tensors\n",
    "X = torch.tensor(normalized_features, dtype=torch.float32)\n",
    "y = torch.tensor(target.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Define the Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# Define the Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "input_dim = X.shape[1]\n",
    "latent_dim = 20  # Size of the noise vector\n",
    "\n",
    "generator = Generator(latent_dim, input_dim)\n",
    "discriminator = Discriminator(input_dim)\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "\n",
    "# Loss function\n",
    "adversarial_loss = nn.BCELoss()\n",
    "\n",
    "# Training the GAN\n",
    "num_epochs = 1000\n",
    "batch_size = 64\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    permutation = torch.randperm(X.size()[0])\n",
    "    for i in range(0, X.size()[0], batch_size):\n",
    "        # Train Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        real_data = X[permutation[i:i + batch_size]]\n",
    "        real_labels = torch.ones((real_data.size(0), 1))\n",
    "        fake_labels = torch.zeros((real_data.size(0), 1))\n",
    "        \n",
    "        noise = torch.randn((real_data.size(0), latent_dim))\n",
    "        fake_data = generator(noise)\n",
    "        \n",
    "        real_loss = adversarial_loss(discriminator(real_data), real_labels)\n",
    "        fake_loss = adversarial_loss(discriminator(fake_data.detach()), fake_labels)\n",
    "        d_loss = real_loss + fake_loss\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Train Generator\n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        noise = torch.randn((real_data.size(0), latent_dim))\n",
    "        fake_data = generator(noise)\n",
    "        g_loss = adversarial_loss(discriminator(fake_data), real_labels)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch [{epoch}/{num_epochs}] Discriminator Loss: {d_loss.item():.4f}, Generator Loss: {g_loss.item():.4f}\")\n",
    "\n",
    "# Sample synthetic data\n",
    "num_samples = len(data)\n",
    "noise = torch.randn((num_samples, latent_dim))\n",
    "with torch.no_grad():\n",
    "    synthetic_data = generator(noise).numpy()\n",
    "\n",
    "# Inverse transform the normalized features\n",
    "synthetic_features = scaler.inverse_transform(synthetic_data)\n",
    "synthetic_df = pd.DataFrame(synthetic_features, columns=features.columns)\n",
    "synthetic_df['Outcome'] = target.values\n",
    "\n",
    "# Statistical comparison\n",
    "def compare_statistics(original, synthetic):\n",
    "    stats = {\n",
    "        \"mean\": {},\n",
    "        \"std\": {},\n",
    "        \"min\": {},\n",
    "        \"max\": {},\n",
    "    }\n",
    "\n",
    "    for column in original.columns:\n",
    "        orig_stats = original[column].describe()\n",
    "        synth_stats = synthetic[column].describe()\n",
    "\n",
    "        stats[\"mean\"][column] = (orig_stats[\"mean\"], synth_stats[\"mean\"])\n",
    "        stats[\"std\"][column] = (orig_stats[\"std\"], synth_stats[\"std\"])\n",
    "        stats[\"min\"][column] = (orig_stats[\"min\"], synth_stats[\"min\"])\n",
    "        stats[\"max\"][column] = (orig_stats[\"max\"], synth_stats[\"max\"])\n",
    "\n",
    "    return stats\n",
    "\n",
    "def percent_difference(orig_val, synth_val):\n",
    "    return abs(orig_val - synth_val) / orig_val * 100\n",
    "\n",
    "# Compute statistics\n",
    "stats = compare_statistics(data, synthetic_df)\n",
    "\n",
    "# Print results and percent differences\n",
    "for stat_type, columns in stats.items():\n",
    "    print(f\"\\n{stat_type.upper()}:\")\n",
    "    for column, values in columns.items():\n",
    "        orig_val, synth_val = values\n",
    "        diff = percent_difference(orig_val, synth_val)\n",
    "        print(f\"{column} - Original: {orig_val:.4f}, Synthetic: {synth_val:.4f}, Percent Difference: {diff:.2f}%\")\n",
    "\n",
    "# Kolmogorov-Smirnov Test\n",
    "print(\"\\nKOLMOGOROV-SMIRNOV TEST:\")\n",
    "for column in features.columns:\n",
    "    stat, p_value = ks_2samp(data[column], synthetic_df[column])\n",
    "    print(f\"{column} - K-S Statistic: {stat:.4f}, P-value: {p_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbitrary dataset script below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "class GAN:\n",
    "    def __init__(self, input_dim, latent_dim=20, lr=0.0002):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        self.generator = self.Generator(input_dim, latent_dim)\n",
    "        self.discriminator = self.Discriminator(input_dim)\n",
    "        \n",
    "        self.optimizer_G = optim.Adam(self.generator.parameters(), lr=lr)\n",
    "        self.optimizer_D = optim.Adam(self.discriminator.parameters(), lr=lr)\n",
    "        self.adversarial_loss = nn.BCELoss()\n",
    "\n",
    "    class Generator(nn.Module):\n",
    "        def __init__(self, input_dim, latent_dim):\n",
    "            super(GAN.Generator, self).__init__()\n",
    "            self.network = nn.Sequential(\n",
    "                nn.Linear(latent_dim, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, input_dim)\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.network(x)\n",
    "\n",
    "    class Discriminator(nn.Module):\n",
    "        def __init__(self, input_dim):\n",
    "            super(GAN.Discriminator, self).__init__()\n",
    "            self.network = nn.Sequential(\n",
    "                nn.Linear(input_dim, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 1),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.network(x)\n",
    "\n",
    "    def train(self, X, num_epochs=1000, batch_size=64):\n",
    "        for epoch in range(num_epochs):\n",
    "            permutation = torch.randperm(X.size()[0])\n",
    "            for i in range(0, X.size()[0], batch_size):\n",
    "                # Train Discriminator\n",
    "                self.optimizer_D.zero_grad()\n",
    "                \n",
    "                real_data = X[permutation[i:i + batch_size]]\n",
    "                real_labels = torch.ones((real_data.size(0), 1))\n",
    "                fake_labels = torch.zeros((real_data.size(0), 1))\n",
    "                \n",
    "                noise = torch.randn((real_data.size(0), self.latent_dim))\n",
    "                fake_data = self.generator(noise)\n",
    "                \n",
    "                real_loss = self.adversarial_loss(self.discriminator(real_data), real_labels)\n",
    "                fake_loss = self.adversarial_loss(self.discriminator(fake_data.detach()), fake_labels)\n",
    "                d_loss = real_loss + fake_loss\n",
    "                d_loss.backward()\n",
    "                self.optimizer_D.step()\n",
    "\n",
    "                # Train Generator\n",
    "                self.optimizer_G.zero_grad()\n",
    "                \n",
    "                noise = torch.randn((real_data.size(0), self.latent_dim))\n",
    "                fake_data = self.generator(noise)\n",
    "                g_loss = self.adversarial_loss(self.discriminator(fake_data), real_labels)\n",
    "                g_loss.backward()\n",
    "                self.optimizer_G.step()\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"Epoch [{epoch}/{num_epochs}] Discriminator Loss: {d_loss.item():.4f}, Generator Loss: {g_loss.item():.4f}\")\n",
    "\n",
    "    def sample(self, num_samples):\n",
    "        noise = torch.randn((num_samples, self.latent_dim))\n",
    "        with torch.no_grad():\n",
    "            return self.generator(noise).numpy()\n",
    "\n",
    "def compare_statistics(original, synthetic):\n",
    "    stats = {\n",
    "        \"mean\": {},\n",
    "        \"std\": {},\n",
    "        \"min\": {},\n",
    "        \"max\": {},\n",
    "    }\n",
    "\n",
    "    for column in original.columns:\n",
    "        orig_stats = original[column].describe()\n",
    "        synth_stats = synthetic[column].describe()\n",
    "\n",
    "        stats[\"mean\"][column] = (orig_stats[\"mean\"], synth_stats[\"mean\"])\n",
    "        stats[\"std\"][column] = (orig_stats[\"std\"], synth_stats[\"std\"])\n",
    "        stats[\"min\"][column] = (orig_stats[\"min\"], synth_stats[\"min\"])\n",
    "        stats[\"max\"][column] = (orig_stats[\"max\"], synth_stats[\"max\"])\n",
    "\n",
    "    return stats\n",
    "\n",
    "def percent_difference(orig_val, synth_val):\n",
    "    return abs(orig_val - synth_val) / orig_val * 100\n",
    "\n",
    "def perform_ks_test(original, synthetic):\n",
    "    ks_results = {}\n",
    "    for column in original.columns:\n",
    "        stat, p_value = ks_2samp(original[column], synthetic[column])\n",
    "        ks_results[column] = (stat, p_value)\n",
    "    return ks_results\n",
    "\n",
    "def produce_synthetic_data(data, num_epochs=1000, batch_size=64, latent_dim=20):\n",
    "    # Separate features and target if 'Outcome' column exists\n",
    "    if 'Outcome' in data.columns:\n",
    "        features = data.drop(columns=['Outcome'])\n",
    "        target = data['Outcome']\n",
    "    else:\n",
    "        features = data\n",
    "        target = None\n",
    "\n",
    "    # Normalize the features\n",
    "    scaler = StandardScaler()\n",
    "    normalized_features = scaler.fit_transform(features)\n",
    "\n",
    "    # Convert to torch tensors\n",
    "    X = torch.tensor(normalized_features, dtype=torch.float32)\n",
    "\n",
    "    # Initialize and train GAN\n",
    "    gan = GAN(input_dim=X.shape[1], latent_dim=latent_dim)\n",
    "    gan.train(X, num_epochs=num_epochs, batch_size=batch_size)\n",
    "\n",
    "    # Sample synthetic data\n",
    "    synthetic_data = gan.sample(len(data))\n",
    "\n",
    "    # Inverse transform the normalized features\n",
    "    synthetic_features = scaler.inverse_transform(synthetic_data)\n",
    "    synthetic_df = pd.DataFrame(synthetic_features, columns=features.columns)\n",
    "    if target is not None:\n",
    "        synthetic_df['Outcome'] = target.values\n",
    "\n",
    "    # Statistical comparison\n",
    "    stats = compare_statistics(data, synthetic_df)\n",
    "\n",
    "    # Print results and percent differences\n",
    "    for stat_type, columns in stats.items():\n",
    "        print(f\"\\n{stat_type.upper()}:\")\n",
    "        for column, values in columns.items():\n",
    "            orig_val, synth_val = values\n",
    "            diff = percent_difference(orig_val, synth_val)\n",
    "            print(f\"{column} - Original: {orig_val:.4f}, Synthetic: {synth_val:.4f}, Percent Difference: {diff:.2f}%\")\n",
    "\n",
    "    # Kolmogorov-Smirnov Test\n",
    "    print(\"\\nKOLMOGOROV-SMIRNOV TEST:\")\n",
    "    ks_results = perform_ks_test(data, synthetic_df)\n",
    "    for column, (stat, p_value) in ks_results.items():\n",
    "        print(f\"{column} - K-S Statistic: {stat:.4f}, P-value: {p_value:.4f}\")\n",
    "\n",
    "    return synthetic_df\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    data = pd.read_csv('/path/to/your/dataset.csv')\n",
    "    synthetic_data = produce_synthetic_data(data, num_epochs=1000, batch_size=64, latent_dim=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runing on an arbitrary dataset below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
