{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN:\n",
      "Pregnancies - Original: 3.8451, Synthetic: 2.9332, Percent Difference: 23.72%\n",
      "Glucose - Original: 120.8945, Synthetic: 107.6811, Percent Difference: 10.93%\n",
      "BloodPressure - Original: 69.1055, Synthetic: 65.4201, Percent Difference: 5.33%\n",
      "SkinThickness - Original: 20.5365, Synthetic: 15.0024, Percent Difference: 26.95%\n",
      "Insulin - Original: 79.7995, Synthetic: 70.3147, Percent Difference: 11.89%\n",
      "BMI - Original: 31.9926, Synthetic: 30.4713, Percent Difference: 4.76%\n",
      "DiabetesPedigreeFunction - Original: 0.4719, Synthetic: 0.2709, Percent Difference: 42.60%\n",
      "Age - Original: 33.2409, Synthetic: 39.2300, Percent Difference: 18.02%\n",
      "Outcome - Original: 0.3490, Synthetic: 0.1824, Percent Difference: 47.73%\n",
      "\n",
      "STD:\n",
      "Pregnancies - Original: 3.3696, Synthetic: 3.5410, Percent Difference: 5.09%\n",
      "Glucose - Original: 31.9726, Synthetic: 31.1526, Percent Difference: 2.56%\n",
      "BloodPressure - Original: 19.3558, Synthetic: 20.8618, Percent Difference: 7.78%\n",
      "SkinThickness - Original: 15.9522, Synthetic: 17.0571, Percent Difference: 6.93%\n",
      "Insulin - Original: 115.2440, Synthetic: 132.1841, Percent Difference: 14.70%\n",
      "BMI - Original: 7.8842, Synthetic: 10.4671, Percent Difference: 32.76%\n",
      "DiabetesPedigreeFunction - Original: 0.3313, Synthetic: 0.3209, Percent Difference: 3.13%\n",
      "Age - Original: 11.7602, Synthetic: 16.0306, Percent Difference: 36.31%\n",
      "Outcome - Original: 0.4770, Synthetic: 0.3862, Percent Difference: 19.03%\n",
      "\n",
      "MIN:\n",
      "Pregnancies - Original: 0.0000, Synthetic: -2.6885, Percent Difference: inf%\n",
      "Glucose - Original: 0.0000, Synthetic: -80.1433, Percent Difference: inf%\n",
      "BloodPressure - Original: 0.0000, Synthetic: -44.1264, Percent Difference: inf%\n",
      "SkinThickness - Original: 0.0000, Synthetic: -6.6188, Percent Difference: inf%\n",
      "Insulin - Original: 0.0000, Synthetic: -217.4623, Percent Difference: inf%\n",
      "BMI - Original: 0.0000, Synthetic: -32.9149, Percent Difference: inf%\n",
      "DiabetesPedigreeFunction - Original: 0.0780, Synthetic: -0.8327, Percent Difference: 1167.58%\n",
      "Age - Original: 21.0000, Synthetic: 16.5096, Percent Difference: 21.38%\n",
      "Outcome - Original: 0.0000, Synthetic: 0.0000, Percent Difference: nan%\n",
      "\n",
      "MAX:\n",
      "Pregnancies - Original: 17.0000, Synthetic: 17.8508, Percent Difference: 5.00%\n",
      "Glucose - Original: 199.0000, Synthetic: 234.1902, Percent Difference: 17.68%\n",
      "BloodPressure - Original: 122.0000, Synthetic: 144.2739, Percent Difference: 18.26%\n",
      "SkinThickness - Original: 99.0000, Synthetic: 66.0876, Percent Difference: 33.24%\n",
      "Insulin - Original: 846.0000, Synthetic: 1022.3073, Percent Difference: 20.84%\n",
      "BMI - Original: 67.1000, Synthetic: 73.8208, Percent Difference: 10.02%\n",
      "DiabetesPedigreeFunction - Original: 2.4200, Synthetic: 3.4824, Percent Difference: 43.90%\n",
      "Age - Original: 81.0000, Synthetic: 89.6536, Percent Difference: 10.68%\n",
      "Outcome - Original: 1.0000, Synthetic: 1.0000, Percent Difference: 0.00%\n",
      "\n",
      "KOLMOGOROV-SMIRNOV TEST:\n",
      "Pregnancies - K-S Statistic: 0.2176, P-value: 0.0000\n",
      "Glucose - K-S Statistic: 0.1931, P-value: 0.0000\n",
      "BloodPressure - K-S Statistic: 0.1916, P-value: 0.0000\n",
      "SkinThickness - K-S Statistic: 0.2707, P-value: 0.0000\n",
      "Insulin - K-S Statistic: 0.2483, P-value: 0.0000\n",
      "BMI - K-S Statistic: 0.1222, P-value: 0.0000\n",
      "DiabetesPedigreeFunction - K-S Statistic: 0.3634, P-value: 0.0000\n",
      "Age - K-S Statistic: 0.2160, P-value: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gk/8dd7zppx4vdg26x_p2w7pkn40000gn/T/ipykernel_7642/3285819046.py:59: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return abs(orig_val - synth_val) / orig_val * 100\n",
      "/var/folders/gk/8dd7zppx4vdg26x_p2w7pkn40000gn/T/ipykernel_7642/3285819046.py:59: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return abs(orig_val - synth_val) / orig_val * 100\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ctgan import CTGAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import ks_2samp\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Separate features and target\n",
    "features = data.drop(columns=['Outcome'])\n",
    "target = data['Outcome']\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "normalized_features = scaler.fit_transform(features)\n",
    "\n",
    "# Combine normalized features with target for CTGAN\n",
    "normalized_data = pd.DataFrame(normalized_features, columns=features.columns)\n",
    "normalized_data['Outcome'] = target.values\n",
    "\n",
    "# Initialize and train CTGAN\n",
    "ctgan = CTGAN()\n",
    "ctgan.fit(normalized_data, epochs=1000)\n",
    "\n",
    "# Sample synthetic data\n",
    "num_samples = len(data)\n",
    "synthetic_data = ctgan.sample(10000)\n",
    "\n",
    "# Inverse transform the normalized features\n",
    "synthetic_features = synthetic_data.drop(columns=['Outcome'])\n",
    "synthetic_features = scaler.inverse_transform(synthetic_features)\n",
    "synthetic_data[features.columns] = synthetic_features\n",
    "\n",
    "# Convert synthetic data to the same format as original data\n",
    "synthetic_data = synthetic_data[normalized_data.columns]\n",
    "\n",
    "# Statistical comparison\n",
    "def compare_statistics(original, synthetic):\n",
    "    stats = {\n",
    "        \"mean\": {},\n",
    "        \"std\": {},\n",
    "        \"min\": {},\n",
    "        \"max\": {},\n",
    "    }\n",
    "\n",
    "    for column in original.columns:\n",
    "        orig_stats = original[column].describe()\n",
    "        synth_stats = synthetic[column].describe()\n",
    "\n",
    "        stats[\"mean\"][column] = (orig_stats[\"mean\"], synth_stats[\"mean\"])\n",
    "        stats[\"std\"][column] = (orig_stats[\"std\"], synth_stats[\"std\"])\n",
    "        stats[\"min\"][column] = (orig_stats[\"min\"], synth_stats[\"min\"])\n",
    "        stats[\"max\"][column] = (orig_stats[\"max\"], synth_stats[\"max\"])\n",
    "\n",
    "    return stats\n",
    "\n",
    "def percent_difference(orig_val, synth_val):\n",
    "    return abs(orig_val - synth_val) / orig_val * 100\n",
    "\n",
    "# Compute statistics\n",
    "stats = compare_statistics(data, synthetic_data)\n",
    "\n",
    "# Print results and percent differences\n",
    "for stat_type, columns in stats.items():\n",
    "    print(f\"\\n{stat_type.upper()}:\")\n",
    "    for column, values in columns.items():\n",
    "        orig_val, synth_val = values\n",
    "        diff = percent_difference(orig_val, synth_val)\n",
    "        print(f\"{column} - Original: {orig_val:.4f}, Synthetic: {synth_val:.4f}, Percent Difference: {diff:.2f}%\")\n",
    "\n",
    "print(\"\\nKOLMOGOROV-SMIRNOV TEST:\")\n",
    "for column in features.columns:\n",
    "    stat, p_value = ks_2samp(data[column], synthetic_data[column])\n",
    "    print(f\"{column} - K-S Statistic: {stat:.4f}, P-value: {p_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN:\n",
      "Pregnancies - Original: 3.8451, Synthetic: 3.8466, Percent Difference: 0.04%\n",
      "Glucose - Original: 120.8945, Synthetic: 121.3848, Percent Difference: 0.41%\n",
      "BloodPressure - Original: 69.1055, Synthetic: 69.0705, Percent Difference: 0.05%\n",
      "SkinThickness - Original: 20.5365, Synthetic: 20.6119, Percent Difference: 0.37%\n",
      "Insulin - Original: 79.7995, Synthetic: 80.6122, Percent Difference: 1.02%\n",
      "BMI - Original: 31.9926, Synthetic: 31.9545, Percent Difference: 0.12%\n",
      "DiabetesPedigreeFunction - Original: 0.4719, Synthetic: 0.4703, Percent Difference: 0.34%\n",
      "Age - Original: 33.2409, Synthetic: 33.2985, Percent Difference: 0.17%\n",
      "Outcome - Original: 0.3490, Synthetic: 0.3490, Percent Difference: 0.00%\n",
      "\n",
      "STD:\n",
      "Pregnancies - Original: 3.3696, Synthetic: 3.3737, Percent Difference: 0.12%\n",
      "Glucose - Original: 31.9726, Synthetic: 31.9484, Percent Difference: 0.08%\n",
      "BloodPressure - Original: 19.3558, Synthetic: 19.3886, Percent Difference: 0.17%\n",
      "SkinThickness - Original: 15.9522, Synthetic: 15.9914, Percent Difference: 0.25%\n",
      "Insulin - Original: 115.2440, Synthetic: 115.5243, Percent Difference: 0.24%\n",
      "BMI - Original: 7.8842, Synthetic: 7.8717, Percent Difference: 0.16%\n",
      "DiabetesPedigreeFunction - Original: 0.3313, Synthetic: 0.3305, Percent Difference: 0.24%\n",
      "Age - Original: 11.7602, Synthetic: 11.7952, Percent Difference: 0.30%\n",
      "Outcome - Original: 0.4770, Synthetic: 0.4770, Percent Difference: 0.00%\n",
      "\n",
      "MIN:\n",
      "Pregnancies - Original: 0.0000, Synthetic: -0.0495, Percent Difference: inf%\n",
      "Glucose - Original: 0.0000, Synthetic: 1.1891, Percent Difference: inf%\n",
      "BloodPressure - Original: 0.0000, Synthetic: -0.4486, Percent Difference: inf%\n",
      "SkinThickness - Original: 0.0000, Synthetic: -0.2701, Percent Difference: inf%\n",
      "Insulin - Original: 0.0000, Synthetic: -1.8210, Percent Difference: inf%\n",
      "BMI - Original: 0.0000, Synthetic: -0.0619, Percent Difference: inf%\n",
      "DiabetesPedigreeFunction - Original: 0.0780, Synthetic: 0.0802, Percent Difference: 2.77%\n",
      "Age - Original: 21.0000, Synthetic: 20.8147, Percent Difference: 0.88%\n",
      "Outcome - Original: 0.0000, Synthetic: 0.0000, Percent Difference: nan%\n",
      "\n",
      "MAX:\n",
      "Pregnancies - Original: 17.0000, Synthetic: 17.0123, Percent Difference: 0.07%\n",
      "Glucose - Original: 199.0000, Synthetic: 199.5909, Percent Difference: 0.30%\n",
      "BloodPressure - Original: 122.0000, Synthetic: 121.9172, Percent Difference: 0.07%\n",
      "SkinThickness - Original: 99.0000, Synthetic: 99.3296, Percent Difference: 0.33%\n",
      "Insulin - Original: 846.0000, Synthetic: 851.0678, Percent Difference: 0.60%\n",
      "BMI - Original: 67.1000, Synthetic: 67.0136, Percent Difference: 0.13%\n",
      "DiabetesPedigreeFunction - Original: 2.4200, Synthetic: 2.4119, Percent Difference: 0.33%\n",
      "Age - Original: 81.0000, Synthetic: 81.1350, Percent Difference: 0.17%\n",
      "Outcome - Original: 1.0000, Synthetic: 1.0000, Percent Difference: 0.00%\n",
      "\n",
      "KOLMOGOROV-SMIRNOV TEST:\n",
      "Pregnancies - K-S Statistic: 0.0938, P-value: 0.0023\n",
      "Glucose - K-S Statistic: 0.0221, P-value: 0.9919\n",
      "BloodPressure - K-S Statistic: 0.0456, P-value: 0.4026\n",
      "SkinThickness - K-S Statistic: 0.1862, P-value: 0.0000\n",
      "Insulin - K-S Statistic: 0.3568, P-value: 0.0000\n",
      "BMI - K-S Statistic: 0.0143, P-value: 1.0000\n",
      "DiabetesPedigreeFunction - K-S Statistic: 0.0130, P-value: 1.0000\n",
      "Age - K-S Statistic: 0.0599, P-value: 0.1272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gk/8dd7zppx4vdg26x_p2w7pkn40000gn/T/ipykernel_7642/905815949.py:95: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return abs(orig_val - synth_val) / orig_val * 100\n",
      "/var/folders/gk/8dd7zppx4vdg26x_p2w7pkn40000gn/T/ipykernel_7642/905815949.py:95: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return abs(orig_val - synth_val) / orig_val * 100\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Separate features and target\n",
    "features = data.drop(columns=['Outcome'])\n",
    "target = data['Outcome']\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "normalized_features = scaler.fit_transform(features)\n",
    "\n",
    "# Convert to torch tensors\n",
    "X = torch.tensor(normalized_features, dtype=torch.float32)\n",
    "y = torch.tensor(target.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Define the neural network\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "input_dim = X.shape[1]\n",
    "output_dim = X.shape[1]\n",
    "\n",
    "generator = Generator(input_dim, output_dim)\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = optim.Adam(generator.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Train the neural network\n",
    "num_epochs = 1000\n",
    "batch_size = 64\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    permutation = torch.randperm(X.size()[0])\n",
    "    for i in range(0, X.size()[0], batch_size):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        indices = permutation[i:i + batch_size]\n",
    "        batch_x, batch_y = X[indices], y[indices]\n",
    "\n",
    "        outputs = generator(batch_x)\n",
    "        loss = criterion(outputs, batch_x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Sample synthetic data\n",
    "with torch.no_grad():\n",
    "    synthetic_data = generator(X).numpy()\n",
    "\n",
    "# Inverse transform the normalized features\n",
    "synthetic_features = scaler.inverse_transform(synthetic_data)\n",
    "synthetic_df = pd.DataFrame(synthetic_features, columns=features.columns)\n",
    "synthetic_df['Outcome'] = target.values\n",
    "\n",
    "# Statistical comparison\n",
    "def compare_statistics(original, synthetic):\n",
    "    stats = {\n",
    "        \"mean\": {},\n",
    "        \"std\": {},\n",
    "        \"min\": {},\n",
    "        \"max\": {},\n",
    "    }\n",
    "\n",
    "    for column in original.columns:\n",
    "        orig_stats = original[column].describe()\n",
    "        synth_stats = synthetic[column].describe()\n",
    "\n",
    "        stats[\"mean\"][column] = (orig_stats[\"mean\"], synth_stats[\"mean\"])\n",
    "        stats[\"std\"][column] = (orig_stats[\"std\"], synth_stats[\"std\"])\n",
    "        stats[\"min\"][column] = (orig_stats[\"min\"], synth_stats[\"min\"])\n",
    "        stats[\"max\"][column] = (orig_stats[\"max\"], synth_stats[\"max\"])\n",
    "\n",
    "    return stats\n",
    "\n",
    "def percent_difference(orig_val, synth_val):\n",
    "    return abs(orig_val - synth_val) / orig_val * 100\n",
    "\n",
    "# Compute statistics\n",
    "stats = compare_statistics(data, synthetic_df)\n",
    "\n",
    "# Print results and percent differences\n",
    "for stat_type, columns in stats.items():\n",
    "    print(f\"\\n{stat_type.upper()}:\")\n",
    "    for column, values in columns.items():\n",
    "        orig_val, synth_val = values\n",
    "        diff = percent_difference(orig_val, synth_val)\n",
    "        print(f\"{column} - Original: {orig_val:.4f}, Synthetic: {synth_val:.4f}, Percent Difference: {diff:.2f}%\")\n",
    "\n",
    "# Kolmogorov-Smirnov Test\n",
    "print(\"\\nKOLMOGOROV-SMIRNOV TEST:\")\n",
    "for column in features.columns:\n",
    "    stat, p_value = ks_2samp(data[column], synthetic_df[column])\n",
    "    print(f\"{column} - K-S Statistic: {stat:.4f}, P-value: {p_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/1000] Discriminator Loss: 1.3351, Generator Loss: 0.6770\n",
      "Epoch [100/1000] Discriminator Loss: 0.8685, Generator Loss: 0.9934\n",
      "Epoch [200/1000] Discriminator Loss: 0.7726, Generator Loss: 1.6361\n",
      "Epoch [300/1000] Discriminator Loss: 0.6548, Generator Loss: 1.4359\n",
      "Epoch [400/1000] Discriminator Loss: 0.6083, Generator Loss: 1.8280\n",
      "Epoch [500/1000] Discriminator Loss: 0.7406, Generator Loss: 1.4959\n",
      "Epoch [600/1000] Discriminator Loss: 1.0855, Generator Loss: 1.5295\n",
      "Epoch [700/1000] Discriminator Loss: 1.0166, Generator Loss: 1.3697\n",
      "Epoch [800/1000] Discriminator Loss: 1.2088, Generator Loss: 0.9091\n",
      "Epoch [900/1000] Discriminator Loss: 1.3762, Generator Loss: 0.9508\n",
      "\n",
      "MEAN:\n",
      "Pregnancies - Original: 3.8451, Synthetic: 3.7287, Percent Difference: 3.03%\n",
      "Glucose - Original: 120.8945, Synthetic: 106.3909, Percent Difference: 12.00%\n",
      "BloodPressure - Original: 69.1055, Synthetic: 67.7193, Percent Difference: 2.01%\n",
      "SkinThickness - Original: 20.5365, Synthetic: 21.0729, Percent Difference: 2.61%\n",
      "Insulin - Original: 79.7995, Synthetic: 122.9715, Percent Difference: 54.10%\n",
      "BMI - Original: 31.9926, Synthetic: 33.8269, Percent Difference: 5.73%\n",
      "DiabetesPedigreeFunction - Original: 0.4719, Synthetic: 0.4398, Percent Difference: 6.81%\n",
      "Age - Original: 33.2409, Synthetic: 29.8226, Percent Difference: 10.28%\n",
      "Outcome - Original: 0.3490, Synthetic: 0.3490, Percent Difference: 0.00%\n",
      "\n",
      "STD:\n",
      "Pregnancies - Original: 3.3696, Synthetic: 2.5986, Percent Difference: 22.88%\n",
      "Glucose - Original: 31.9726, Synthetic: 23.7015, Percent Difference: 25.87%\n",
      "BloodPressure - Original: 19.3558, Synthetic: 6.8743, Percent Difference: 64.48%\n",
      "SkinThickness - Original: 15.9522, Synthetic: 12.2176, Percent Difference: 23.41%\n",
      "Insulin - Original: 115.2440, Synthetic: 113.6750, Percent Difference: 1.36%\n",
      "BMI - Original: 7.8842, Synthetic: 5.8383, Percent Difference: 25.95%\n",
      "DiabetesPedigreeFunction - Original: 0.3313, Synthetic: 0.2564, Percent Difference: 22.60%\n",
      "Age - Original: 11.7602, Synthetic: 11.5599, Percent Difference: 1.70%\n",
      "Outcome - Original: 0.4770, Synthetic: 0.4770, Percent Difference: 0.00%\n",
      "\n",
      "MIN:\n",
      "Pregnancies - Original: 0.0000, Synthetic: -0.7859, Percent Difference: inf%\n",
      "Glucose - Original: 0.0000, Synthetic: 55.2954, Percent Difference: inf%\n",
      "BloodPressure - Original: 0.0000, Synthetic: 30.9678, Percent Difference: inf%\n",
      "SkinThickness - Original: 0.0000, Synthetic: -21.1231, Percent Difference: inf%\n",
      "Insulin - Original: 0.0000, Synthetic: -19.0150, Percent Difference: inf%\n",
      "BMI - Original: 0.0000, Synthetic: 16.2513, Percent Difference: inf%\n",
      "DiabetesPedigreeFunction - Original: 0.0780, Synthetic: -0.0494, Percent Difference: 163.36%\n",
      "Age - Original: 21.0000, Synthetic: 11.8673, Percent Difference: 43.49%\n",
      "Outcome - Original: 0.0000, Synthetic: 0.0000, Percent Difference: nan%\n",
      "\n",
      "MAX:\n",
      "Pregnancies - Original: 17.0000, Synthetic: 14.3527, Percent Difference: 15.57%\n",
      "Glucose - Original: 199.0000, Synthetic: 183.7170, Percent Difference: 7.68%\n",
      "BloodPressure - Original: 122.0000, Synthetic: 84.8030, Percent Difference: 30.49%\n",
      "SkinThickness - Original: 99.0000, Synthetic: 49.7680, Percent Difference: 49.73%\n",
      "Insulin - Original: 846.0000, Synthetic: 656.6526, Percent Difference: 22.38%\n",
      "BMI - Original: 67.1000, Synthetic: 55.3554, Percent Difference: 17.50%\n",
      "DiabetesPedigreeFunction - Original: 2.4200, Synthetic: 1.7605, Percent Difference: 27.25%\n",
      "Age - Original: 81.0000, Synthetic: 88.6225, Percent Difference: 9.41%\n",
      "Outcome - Original: 1.0000, Synthetic: 1.0000, Percent Difference: 0.00%\n",
      "\n",
      "KOLMOGOROV-SMIRNOV TEST:\n",
      "Pregnancies - K-S Statistic: 0.2448, P-value: 0.0000\n",
      "Glucose - K-S Statistic: 0.2188, P-value: 0.0000\n",
      "BloodPressure - K-S Statistic: 0.3008, P-value: 0.0000\n",
      "SkinThickness - K-S Statistic: 0.2422, P-value: 0.0000\n",
      "Insulin - K-S Statistic: 0.4740, P-value: 0.0000\n",
      "BMI - K-S Statistic: 0.1576, P-value: 0.0000\n",
      "DiabetesPedigreeFunction - K-S Statistic: 0.1406, P-value: 0.0000\n",
      "Age - K-S Statistic: 0.2435, P-value: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gk/8dd7zppx4vdg26x_p2w7pkn40000gn/T/ipykernel_7642/656960758.py:135: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return abs(orig_val - synth_val) / orig_val * 100\n",
      "/var/folders/gk/8dd7zppx4vdg26x_p2w7pkn40000gn/T/ipykernel_7642/656960758.py:135: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return abs(orig_val - synth_val) / orig_val * 100\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Separate features and target\n",
    "features = data.drop(columns=['Outcome'])\n",
    "target = data['Outcome']\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "normalized_features = scaler.fit_transform(features)\n",
    "\n",
    "# Convert to torch tensors\n",
    "X = torch.tensor(normalized_features, dtype=torch.float32)\n",
    "y = torch.tensor(target.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Define the Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# Define the Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "input_dim = X.shape[1]\n",
    "latent_dim = 20  # Size of the noise vector\n",
    "\n",
    "generator = Generator(latent_dim, input_dim)\n",
    "discriminator = Discriminator(input_dim)\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "\n",
    "# Loss function\n",
    "adversarial_loss = nn.BCELoss()\n",
    "\n",
    "# Training the GAN\n",
    "num_epochs = 1000\n",
    "batch_size = 64\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    permutation = torch.randperm(X.size()[0])\n",
    "    for i in range(0, X.size()[0], batch_size):\n",
    "        # Train Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        real_data = X[permutation[i:i + batch_size]]\n",
    "        real_labels = torch.ones((real_data.size(0), 1))\n",
    "        fake_labels = torch.zeros((real_data.size(0), 1))\n",
    "        \n",
    "        noise = torch.randn((real_data.size(0), latent_dim))\n",
    "        fake_data = generator(noise)\n",
    "        \n",
    "        real_loss = adversarial_loss(discriminator(real_data), real_labels)\n",
    "        fake_loss = adversarial_loss(discriminator(fake_data.detach()), fake_labels)\n",
    "        d_loss = real_loss + fake_loss\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Train Generator\n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        noise = torch.randn((real_data.size(0), latent_dim))\n",
    "        fake_data = generator(noise)\n",
    "        g_loss = adversarial_loss(discriminator(fake_data), real_labels)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch [{epoch}/{num_epochs}] Discriminator Loss: {d_loss.item():.4f}, Generator Loss: {g_loss.item():.4f}\")\n",
    "\n",
    "# Sample synthetic data\n",
    "num_samples = len(data)\n",
    "noise = torch.randn((num_samples, latent_dim))\n",
    "with torch.no_grad():\n",
    "    synthetic_data = generator(noise).numpy()\n",
    "\n",
    "# Inverse transform the normalized features\n",
    "synthetic_features = scaler.inverse_transform(synthetic_data)\n",
    "synthetic_df = pd.DataFrame(synthetic_features, columns=features.columns)\n",
    "synthetic_df['Outcome'] = target.values\n",
    "\n",
    "# Statistical comparison\n",
    "def compare_statistics(original, synthetic):\n",
    "    stats = {\n",
    "        \"mean\": {},\n",
    "        \"std\": {},\n",
    "        \"min\": {},\n",
    "        \"max\": {},\n",
    "    }\n",
    "\n",
    "    for column in original.columns:\n",
    "        orig_stats = original[column].describe()\n",
    "        synth_stats = synthetic[column].describe()\n",
    "\n",
    "        stats[\"mean\"][column] = (orig_stats[\"mean\"], synth_stats[\"mean\"])\n",
    "        stats[\"std\"][column] = (orig_stats[\"std\"], synth_stats[\"std\"])\n",
    "        stats[\"min\"][column] = (orig_stats[\"min\"], synth_stats[\"min\"])\n",
    "        stats[\"max\"][column] = (orig_stats[\"max\"], synth_stats[\"max\"])\n",
    "\n",
    "    return stats\n",
    "\n",
    "def percent_difference(orig_val, synth_val):\n",
    "    return abs(orig_val - synth_val) / orig_val * 100\n",
    "\n",
    "# Compute statistics\n",
    "stats = compare_statistics(data, synthetic_df)\n",
    "\n",
    "# Print results and percent differences\n",
    "for stat_type, columns in stats.items():\n",
    "    print(f\"\\n{stat_type.upper()}:\")\n",
    "    for column, values in columns.items():\n",
    "        orig_val, synth_val = values\n",
    "        diff = percent_difference(orig_val, synth_val)\n",
    "        print(f\"{column} - Original: {orig_val:.4f}, Synthetic: {synth_val:.4f}, Percent Difference: {diff:.2f}%\")\n",
    "\n",
    "# Kolmogorov-Smirnov Test\n",
    "print(\"\\nKOLMOGOROV-SMIRNOV TEST:\")\n",
    "for column in features.columns:\n",
    "    stat, p_value = ks_2samp(data[column], synthetic_df[column])\n",
    "    print(f\"{column} - K-S Statistic: {stat:.4f}, P-value: {p_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbitrary dataset script below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "class GAN:\n",
    "    def __init__(self, input_dim, latent_dim=20, lr=0.0002):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        self.generator = self.Generator(input_dim, latent_dim)\n",
    "        self.discriminator = self.Discriminator(input_dim)\n",
    "        \n",
    "        self.optimizer_G = optim.Adam(self.generator.parameters(), lr=lr)\n",
    "        self.optimizer_D = optim.Adam(self.discriminator.parameters(), lr=lr)\n",
    "        self.adversarial_loss = nn.BCELoss()\n",
    "\n",
    "    class Generator(nn.Module):\n",
    "        def __init__(self, input_dim, latent_dim):\n",
    "            super(GAN.Generator, self).__init__()\n",
    "            self.network = nn.Sequential(\n",
    "                nn.Linear(latent_dim, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, input_dim)\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.network(x)\n",
    "\n",
    "    class Discriminator(nn.Module):\n",
    "        def __init__(self, input_dim):\n",
    "            super(GAN.Discriminator, self).__init__()\n",
    "            self.network = nn.Sequential(\n",
    "                nn.Linear(input_dim, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 1),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.network(x)\n",
    "\n",
    "    def train(self, X, num_epochs=1000, batch_size=64):\n",
    "        for epoch in range(num_epochs):\n",
    "            permutation = torch.randperm(X.size()[0])\n",
    "            for i in range(0, X.size()[0], batch_size):\n",
    "                # Train Discriminator\n",
    "                self.optimizer_D.zero_grad()\n",
    "                \n",
    "                real_data = X[permutation[i:i + batch_size]]\n",
    "                real_labels = torch.ones((real_data.size(0), 1))\n",
    "                fake_labels = torch.zeros((real_data.size(0), 1))\n",
    "                \n",
    "                noise = torch.randn((real_data.size(0), self.latent_dim))\n",
    "                fake_data = self.generator(noise)\n",
    "                \n",
    "                real_loss = self.adversarial_loss(self.discriminator(real_data), real_labels)\n",
    "                fake_loss = self.adversarial_loss(self.discriminator(fake_data.detach()), fake_labels)\n",
    "                d_loss = real_loss + fake_loss\n",
    "                d_loss.backward()\n",
    "                self.optimizer_D.step()\n",
    "\n",
    "                # Train Generator\n",
    "                self.optimizer_G.zero_grad()\n",
    "                \n",
    "                noise = torch.randn((real_data.size(0), self.latent_dim))\n",
    "                fake_data = self.generator(noise)\n",
    "                g_loss = self.adversarial_loss(self.discriminator(fake_data), real_labels)\n",
    "                g_loss.backward()\n",
    "                self.optimizer_G.step()\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"Epoch [{epoch}/{num_epochs}] Discriminator Loss: {d_loss.item():.4f}, Generator Loss: {g_loss.item():.4f}\")\n",
    "\n",
    "    def sample(self, num_samples):\n",
    "        noise = torch.randn((num_samples, self.latent_dim))\n",
    "        with torch.no_grad():\n",
    "            return self.generator(noise).numpy()\n",
    "\n",
    "def compare_statistics(original, synthetic):\n",
    "    stats = {\n",
    "        \"mean\": {},\n",
    "        \"std\": {},\n",
    "        \"min\": {},\n",
    "        \"max\": {},\n",
    "    }\n",
    "\n",
    "    for column in original.columns:\n",
    "        orig_stats = original[column].describe()\n",
    "        synth_stats = synthetic[column].describe()\n",
    "\n",
    "        stats[\"mean\"][column] = (orig_stats[\"mean\"], synth_stats[\"mean\"])\n",
    "        stats[\"std\"][column] = (orig_stats[\"std\"], synth_stats[\"std\"])\n",
    "        stats[\"min\"][column] = (orig_stats[\"min\"], synth_stats[\"min\"])\n",
    "        stats[\"max\"][column] = (orig_stats[\"max\"], synth_stats[\"max\"])\n",
    "\n",
    "    return stats\n",
    "\n",
    "def percent_difference(orig_val, synth_val):\n",
    "    return abs(orig_val - synth_val) / orig_val * 100\n",
    "\n",
    "def perform_ks_test(original, synthetic):\n",
    "    ks_results = {}\n",
    "    for column in original.columns:\n",
    "        stat, p_value = ks_2samp(original[column], synthetic[column])\n",
    "        ks_results[column] = (stat, p_value)\n",
    "    return ks_results\n",
    "\n",
    "def produce_synthetic_data(data, num_epochs=1000, batch_size=64, latent_dim=20):\n",
    "    # Separate features and target if 'Outcome' column exists\n",
    "    if 'Outcome' in data.columns:\n",
    "        features = data.drop(columns=['Outcome'])\n",
    "        target = data['Outcome']\n",
    "    else:\n",
    "        features = data\n",
    "        target = None\n",
    "\n",
    "    # Normalize the features\n",
    "    scaler = StandardScaler()\n",
    "    normalized_features = scaler.fit_transform(features)\n",
    "\n",
    "    # Convert to torch tensors\n",
    "    X = torch.tensor(normalized_features, dtype=torch.float32)\n",
    "\n",
    "    # Initialize and train GAN\n",
    "    gan = GAN(input_dim=X.shape[1], latent_dim=latent_dim)\n",
    "    gan.train(X, num_epochs=num_epochs, batch_size=batch_size)\n",
    "\n",
    "    # Sample synthetic data\n",
    "    synthetic_data = gan.sample(len(data))\n",
    "\n",
    "    # Inverse transform the normalized features\n",
    "    synthetic_features = scaler.inverse_transform(synthetic_data)\n",
    "    synthetic_df = pd.DataFrame(synthetic_features, columns=features.columns)\n",
    "    if target is not None:\n",
    "        synthetic_df['Outcome'] = target.values\n",
    "\n",
    "    # Statistical comparison\n",
    "    stats = compare_statistics(data, synthetic_df)\n",
    "\n",
    "    # Print results and percent differences\n",
    "    for stat_type, columns in stats.items():\n",
    "        print(f\"\\n{stat_type.upper()}:\")\n",
    "        for column, values in columns.items():\n",
    "            orig_val, synth_val = values\n",
    "            diff = percent_difference(orig_val, synth_val)\n",
    "            print(f\"{column} - Original: {orig_val:.4f}, Synthetic: {synth_val:.4f}, Percent Difference: {diff:.2f}%\")\n",
    "\n",
    "    # Kolmogorov-Smirnov Test\n",
    "    print(\"\\nKOLMOGOROV-SMIRNOV TEST:\")\n",
    "    ks_results = perform_ks_test(data, synthetic_df)\n",
    "    for column, (stat, p_value) in ks_results.items():\n",
    "        print(f\"{column} - K-S Statistic: {stat:.4f}, P-value: {p_value:.4f}\")\n",
    "\n",
    "    return synthetic_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runing on an arbitrary dataset below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/1000] Discriminator Loss: 1.3730, Generator Loss: 0.6557\n",
      "Epoch [100/1000] Discriminator Loss: 1.1334, Generator Loss: 0.6959\n",
      "Epoch [200/1000] Discriminator Loss: 1.0905, Generator Loss: 0.9412\n",
      "Epoch [300/1000] Discriminator Loss: 1.1402, Generator Loss: 1.0711\n",
      "Epoch [400/1000] Discriminator Loss: 1.1135, Generator Loss: 1.0673\n",
      "Epoch [500/1000] Discriminator Loss: 1.2576, Generator Loss: 0.9438\n",
      "Epoch [600/1000] Discriminator Loss: 1.3259, Generator Loss: 0.6600\n",
      "Epoch [700/1000] Discriminator Loss: 0.9721, Generator Loss: 1.0521\n",
      "Epoch [800/1000] Discriminator Loss: 1.2036, Generator Loss: 0.8459\n",
      "Epoch [900/1000] Discriminator Loss: 1.3629, Generator Loss: 0.9694\n",
      "\n",
      "MEAN:\n",
      "Pregnancies - Original: 3.8451, Synthetic: -2.0452, Percent Difference: 153.19%\n",
      "Glucose - Original: 120.8945, Synthetic: 125.3675, Percent Difference: 3.70%\n",
      "BloodPressure - Original: 69.1055, Synthetic: 94.9516, Percent Difference: 37.40%\n",
      "SkinThickness - Original: 20.5365, Synthetic: 18.6549, Percent Difference: 9.16%\n",
      "Insulin - Original: 79.7995, Synthetic: 71.4742, Percent Difference: 10.43%\n",
      "BMI - Original: 31.9926, Synthetic: 41.0313, Percent Difference: 28.25%\n",
      "DiabetesPedigreeFunction - Original: 0.4719, Synthetic: 0.4299, Percent Difference: 8.90%\n",
      "Age - Original: 33.2409, Synthetic: 41.6598, Percent Difference: 25.33%\n",
      "Outcome - Original: 0.3490, Synthetic: 0.3490, Percent Difference: 0.00%\n",
      "\n",
      "STD:\n",
      "Pregnancies - Original: 3.3696, Synthetic: 3.4093, Percent Difference: 1.18%\n",
      "Glucose - Original: 31.9726, Synthetic: 28.7028, Percent Difference: 10.23%\n",
      "BloodPressure - Original: 19.3558, Synthetic: 8.8980, Percent Difference: 54.03%\n",
      "SkinThickness - Original: 15.9522, Synthetic: 8.6651, Percent Difference: 45.68%\n",
      "Insulin - Original: 115.2440, Synthetic: 58.4980, Percent Difference: 49.24%\n",
      "BMI - Original: 7.8842, Synthetic: 4.8446, Percent Difference: 38.55%\n",
      "DiabetesPedigreeFunction - Original: 0.3313, Synthetic: 0.0930, Percent Difference: 71.94%\n",
      "Age - Original: 11.7602, Synthetic: 17.9255, Percent Difference: 52.42%\n",
      "Outcome - Original: 0.4770, Synthetic: 0.4770, Percent Difference: 0.00%\n",
      "\n",
      "MIN:\n",
      "Pregnancies - Original: 0.0000, Synthetic: -14.0068, Percent Difference: inf%\n",
      "Glucose - Original: 0.0000, Synthetic: 48.9885, Percent Difference: inf%\n",
      "BloodPressure - Original: 0.0000, Synthetic: 69.6955, Percent Difference: inf%\n",
      "SkinThickness - Original: 0.0000, Synthetic: -8.2639, Percent Difference: inf%\n",
      "Insulin - Original: 0.0000, Synthetic: -98.7905, Percent Difference: inf%\n",
      "BMI - Original: 0.0000, Synthetic: 30.7005, Percent Difference: inf%\n",
      "DiabetesPedigreeFunction - Original: 0.0780, Synthetic: 0.1716, Percent Difference: 120.05%\n",
      "Age - Original: 21.0000, Synthetic: -4.2000, Percent Difference: 120.00%\n",
      "Outcome - Original: 0.0000, Synthetic: 0.0000, Percent Difference: nan%\n",
      "\n",
      "MAX:\n",
      "Pregnancies - Original: 17.0000, Synthetic: 5.4137, Percent Difference: 68.15%\n",
      "Glucose - Original: 199.0000, Synthetic: 214.5905, Percent Difference: 7.83%\n",
      "BloodPressure - Original: 122.0000, Synthetic: 140.2216, Percent Difference: 14.94%\n",
      "SkinThickness - Original: 99.0000, Synthetic: 44.4274, Percent Difference: 55.12%\n",
      "Insulin - Original: 846.0000, Synthetic: 301.6322, Percent Difference: 64.35%\n",
      "BMI - Original: 67.1000, Synthetic: 59.1022, Percent Difference: 11.92%\n",
      "DiabetesPedigreeFunction - Original: 2.4200, Synthetic: 0.7615, Percent Difference: 68.53%\n",
      "Age - Original: 81.0000, Synthetic: 94.4643, Percent Difference: 16.62%\n",
      "Outcome - Original: 1.0000, Synthetic: 1.0000, Percent Difference: 0.00%\n",
      "\n",
      "KOLMOGOROV-SMIRNOV TEST:\n",
      "Pregnancies - K-S Statistic: 0.7005, P-value: 0.0000\n",
      "Glucose - K-S Statistic: 0.1250, P-value: 0.0000\n",
      "BloodPressure - K-S Statistic: 0.7786, P-value: 0.0000\n",
      "SkinThickness - K-S Statistic: 0.2812, P-value: 0.0000\n",
      "Insulin - K-S Statistic: 0.3750, P-value: 0.0000\n",
      "BMI - K-S Statistic: 0.5911, P-value: 0.0000\n",
      "DiabetesPedigreeFunction - K-S Statistic: 0.3164, P-value: 0.0000\n",
      "Age - K-S Statistic: 0.2747, P-value: 0.0000\n",
      "Outcome - K-S Statistic: 0.0000, P-value: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gk/8dd7zppx4vdg26x_p2w7pkn40000gn/T/ipykernel_876/1424367128.py:107: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return abs(orig_val - synth_val) / orig_val * 100\n",
      "/var/folders/gk/8dd7zppx4vdg26x_p2w7pkn40000gn/T/ipykernel_876/1424367128.py:107: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return abs(orig_val - synth_val) / orig_val * 100\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('diabetes.csv')\n",
    "synthetic_data = produce_synthetic_data(data, num_epochs=1000, batch_size=64, latent_dim=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THIS IS TESTING THE DATA FROM THE SCRIPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/10000] | D Loss: 0.6856 | G Loss: 0.7124\n",
      "Epoch [100/10000] | D Loss: 0.0659 | G Loss: 3.1258\n",
      "Epoch [200/10000] | D Loss: 0.2945 | G Loss: 2.9347\n",
      "Epoch [300/10000] | D Loss: 1.0957 | G Loss: 2.1405\n",
      "Epoch [400/10000] | D Loss: 0.2546 | G Loss: 5.5434\n",
      "Epoch [500/10000] | D Loss: 0.6416 | G Loss: 1.4317\n",
      "Epoch [600/10000] | D Loss: 0.9882 | G Loss: 1.6677\n",
      "Epoch [700/10000] | D Loss: 1.1495 | G Loss: 1.0899\n",
      "Epoch [800/10000] | D Loss: 2.1593 | G Loss: 0.8598\n",
      "Epoch [900/10000] | D Loss: 1.0327 | G Loss: 1.3049\n",
      "Epoch [1000/10000] | D Loss: 1.2371 | G Loss: 1.8387\n",
      "Epoch [1100/10000] | D Loss: 0.8889 | G Loss: 1.4128\n",
      "Epoch [1200/10000] | D Loss: 0.8853 | G Loss: 1.4114\n",
      "Epoch [1300/10000] | D Loss: 0.3876 | G Loss: 2.2703\n",
      "Epoch [1400/10000] | D Loss: 0.7472 | G Loss: 2.0396\n",
      "Epoch [1500/10000] | D Loss: 1.1900 | G Loss: 1.2995\n",
      "Epoch [1600/10000] | D Loss: 1.1767 | G Loss: 1.1775\n",
      "Epoch [1700/10000] | D Loss: 1.2654 | G Loss: 1.2170\n",
      "Epoch [1800/10000] | D Loss: 1.2777 | G Loss: 0.9801\n",
      "Epoch [1900/10000] | D Loss: 1.0754 | G Loss: 1.1752\n",
      "Epoch [2000/10000] | D Loss: 1.3507 | G Loss: 0.9106\n",
      "Epoch [2100/10000] | D Loss: 1.4530 | G Loss: 0.9239\n",
      "Epoch [2200/10000] | D Loss: 1.2965 | G Loss: 0.7978\n",
      "Epoch [2300/10000] | D Loss: 1.2208 | G Loss: 1.0890\n",
      "Epoch [2400/10000] | D Loss: 1.2913 | G Loss: 0.7087\n",
      "Epoch [2500/10000] | D Loss: 1.3124 | G Loss: 1.0104\n",
      "Epoch [2600/10000] | D Loss: 1.3880 | G Loss: 0.7090\n",
      "Epoch [2700/10000] | D Loss: 1.3108 | G Loss: 0.7088\n",
      "Epoch [2800/10000] | D Loss: 1.2802 | G Loss: 0.6602\n",
      "Epoch [2900/10000] | D Loss: 1.3119 | G Loss: 1.0533\n",
      "Epoch [3000/10000] | D Loss: 1.2950 | G Loss: 0.8542\n",
      "Epoch [3100/10000] | D Loss: 1.3653 | G Loss: 0.7554\n",
      "Epoch [3200/10000] | D Loss: 1.1735 | G Loss: 0.7997\n",
      "Epoch [3300/10000] | D Loss: 1.4217 | G Loss: 0.7847\n",
      "Epoch [3400/10000] | D Loss: 1.2860 | G Loss: 1.0173\n",
      "Epoch [3500/10000] | D Loss: 1.3810 | G Loss: 0.9996\n",
      "Epoch [3600/10000] | D Loss: 1.3665 | G Loss: 0.9102\n",
      "Epoch [3700/10000] | D Loss: 1.4396 | G Loss: 0.7162\n",
      "Epoch [3800/10000] | D Loss: 1.2464 | G Loss: 0.8839\n",
      "Epoch [3900/10000] | D Loss: 1.2140 | G Loss: 1.0951\n",
      "Epoch [4000/10000] | D Loss: 1.2381 | G Loss: 1.5539\n",
      "Epoch [4100/10000] | D Loss: 1.3097 | G Loss: 0.9086\n",
      "Epoch [4200/10000] | D Loss: 1.1382 | G Loss: 1.0096\n",
      "Epoch [4300/10000] | D Loss: 1.1369 | G Loss: 0.9312\n",
      "Epoch [4400/10000] | D Loss: 1.0304 | G Loss: 1.3091\n",
      "Epoch [4500/10000] | D Loss: 1.2447 | G Loss: 0.9404\n",
      "Epoch [4600/10000] | D Loss: 1.0451 | G Loss: 1.2935\n",
      "Epoch [4700/10000] | D Loss: 1.2285 | G Loss: 1.0735\n",
      "Epoch [4800/10000] | D Loss: 1.1094 | G Loss: 1.2261\n",
      "Epoch [4900/10000] | D Loss: 1.2078 | G Loss: 1.2222\n",
      "Epoch [5000/10000] | D Loss: 1.1700 | G Loss: 0.9499\n",
      "Epoch [5100/10000] | D Loss: 1.1273 | G Loss: 1.1658\n",
      "Epoch [5200/10000] | D Loss: 1.1942 | G Loss: 1.0240\n",
      "Epoch [5300/10000] | D Loss: 1.0791 | G Loss: 1.2671\n",
      "Epoch [5400/10000] | D Loss: 1.2855 | G Loss: 0.8826\n",
      "Epoch [5500/10000] | D Loss: 1.1060 | G Loss: 0.9897\n",
      "Epoch [5600/10000] | D Loss: 1.3096 | G Loss: 0.8620\n",
      "Epoch [5700/10000] | D Loss: 1.1273 | G Loss: 0.8719\n",
      "Epoch [5800/10000] | D Loss: 1.2544 | G Loss: 0.9133\n",
      "Epoch [5900/10000] | D Loss: 1.3229 | G Loss: 0.8614\n",
      "Epoch [6000/10000] | D Loss: 1.3507 | G Loss: 1.0294\n",
      "Epoch [6100/10000] | D Loss: 1.3630 | G Loss: 0.9003\n",
      "Epoch [6200/10000] | D Loss: 1.2440 | G Loss: 0.9110\n",
      "Epoch [6300/10000] | D Loss: 1.2949 | G Loss: 0.9238\n",
      "Epoch [6400/10000] | D Loss: 1.3332 | G Loss: 1.1516\n",
      "Epoch [6500/10000] | D Loss: 1.3659 | G Loss: 0.8019\n",
      "Epoch [6600/10000] | D Loss: 1.2316 | G Loss: 1.0853\n",
      "Epoch [6700/10000] | D Loss: 1.1910 | G Loss: 0.8469\n",
      "Epoch [6800/10000] | D Loss: 1.2360 | G Loss: 0.9178\n",
      "Epoch [6900/10000] | D Loss: 1.3583 | G Loss: 1.1545\n",
      "Epoch [7000/10000] | D Loss: 1.1917 | G Loss: 0.9907\n",
      "Epoch [7100/10000] | D Loss: 1.3209 | G Loss: 1.0226\n",
      "Epoch [7200/10000] | D Loss: 1.3950 | G Loss: 0.8597\n",
      "Epoch [7300/10000] | D Loss: 1.2459 | G Loss: 0.9874\n",
      "Epoch [7400/10000] | D Loss: 1.1499 | G Loss: 1.0285\n",
      "Epoch [7500/10000] | D Loss: 1.2223 | G Loss: 0.7787\n",
      "Epoch [7600/10000] | D Loss: 1.3427 | G Loss: 1.0083\n",
      "Epoch [7700/10000] | D Loss: 1.1268 | G Loss: 1.0041\n",
      "Epoch [7800/10000] | D Loss: 1.2878 | G Loss: 0.9348\n",
      "Epoch [7900/10000] | D Loss: 1.1647 | G Loss: 0.7995\n",
      "Epoch [8000/10000] | D Loss: 1.2354 | G Loss: 0.7960\n",
      "Epoch [8100/10000] | D Loss: 1.0973 | G Loss: 0.9723\n",
      "Epoch [8200/10000] | D Loss: 1.1441 | G Loss: 1.2499\n",
      "Epoch [8300/10000] | D Loss: 1.3206 | G Loss: 1.0564\n",
      "Epoch [8400/10000] | D Loss: 1.1700 | G Loss: 0.9888\n",
      "Epoch [8500/10000] | D Loss: 1.3372 | G Loss: 1.0970\n",
      "Epoch [8600/10000] | D Loss: 1.2642 | G Loss: 0.8886\n",
      "Epoch [8700/10000] | D Loss: 1.1871 | G Loss: 0.9362\n",
      "Epoch [8800/10000] | D Loss: 1.1971 | G Loss: 0.8180\n",
      "Epoch [8900/10000] | D Loss: 1.2738 | G Loss: 0.7233\n",
      "Epoch [9000/10000] | D Loss: 1.1798 | G Loss: 1.1727\n",
      "Epoch [9100/10000] | D Loss: 1.2505 | G Loss: 1.0320\n",
      "Epoch [9200/10000] | D Loss: 1.2386 | G Loss: 0.7679\n",
      "Epoch [9300/10000] | D Loss: 1.2465 | G Loss: 0.7405\n",
      "Epoch [9400/10000] | D Loss: 1.3323 | G Loss: 0.8649\n",
      "Epoch [9500/10000] | D Loss: 1.1534 | G Loss: 0.7975\n",
      "Epoch [9600/10000] | D Loss: 1.2459 | G Loss: 0.8165\n",
      "Epoch [9700/10000] | D Loss: 1.3375 | G Loss: 0.6077\n",
      "Epoch [9800/10000] | D Loss: 1.1656 | G Loss: 1.3197\n",
      "Epoch [9900/10000] | D Loss: 1.2708 | G Loss: 0.8768\n",
      "Synthetic Data Samples:\n",
      "[[ 2.20182915e+01  1.84338455e+02  1.30843719e+02 ... -5.84181070e+00\n",
      "   5.63796349e+01 -2.74446279e-01]\n",
      " [-2.13191962e+00  1.11473167e+02  5.05118980e+01 ...  3.42600256e-01\n",
      "   1.77126541e+01  4.38754940e+00]\n",
      " [ 3.48024559e+00  1.08319557e+02  4.96667023e+01 ...  1.82280421e-01\n",
      "   2.07517433e+01  1.85281920e+00]\n",
      " ...\n",
      " [ 2.34901834e+00  1.62401703e+02  5.47930298e+01 ... -3.17821115e-01\n",
      "   3.06904869e+01  6.20129251e+00]\n",
      " [ 5.68447399e+00  1.76042068e+02  8.26116638e+01 ... -5.68145871e-01\n",
      "   3.49084435e+01  3.48079967e+00]\n",
      " [ 3.83224487e+00  1.21654396e+02  4.72315979e+01 ... -4.30133969e-01\n",
      "   2.64282875e+01  4.43042946e+00]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from GAN_Architecture import train_GAN, Sample_Synthetic_Data\n",
    "\n",
    "# Placeholder path for the CSV file\n",
    "csv_path = 'diabetes.csv'\n",
    "\n",
    "# Train the GAN using the CSV file\n",
    "generator = train_GAN(csv_path)\n",
    "\n",
    "# Sample synthetic data from the trained generator\n",
    "num_samples = 770  # Specify the number of samples you want to generate\n",
    "latent_dim = generator.model[0].in_features  # Extract latent dimension from generator\n",
    "synthetic_data = Sample_Synthetic_Data(generator, num_samples, latent_dim)\n",
    "\n",
    "# Print the synthetic data for verification\n",
    "print(\"Synthetic Data Samples:\")\n",
    "print(synthetic_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
